"""
ë¬´ì‹ ì‚¬ í¬ë¡¤ëŸ¬ v2.2 - ë“€ì–¼ ì €ì¥ (PostgreSQL + OpenSearch)
- PostgreSQL: ì›ë³¸ ë°ì´í„° ë³´ê´€ (Source of Truth)
- OpenSearch: ê²€ìƒ‰ìš© ì¸ë±ìŠ¤
"""
import asyncio
from playwright.async_api import async_playwright
from opensearchpy import OpenSearch, helpers
import re
from datetime import datetime

# ================= ì„¤ì • =================
SEARCH_KEYWORD = "íŒ¨ë”©"
TARGET_URL = f"https://www.musinsa.com/search/goods?keyword={SEARCH_KEYWORD}&gf=A"
SCROLL_COUNT = 3
INDEX_NAME = "musinsa_products"

# ================= OpenSearch ì—°ê²° =================
opensearch_client = OpenSearch(
    hosts=[{'host': 'localhost', 'port': 9201}],
    http_compress=True, use_ssl=False, verify_certs=False
)

# ================= PostgreSQL ì—°ê²° =================
from database.connection import SessionLocal
from database.models import Product, Seller


def save_to_postgres(data_list: list):
    """
    PostgreSQLì— ë°ì´í„° ì €ì¥ (UPSERT - ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸, ì—†ìœ¼ë©´ ìƒì„±)
    """
    db = SessionLocal()
    saved_count = 0
    
    try:
        for data in data_list:
            # URLë¡œ ê¸°ì¡´ ë°ì´í„° ì¡°íšŒ
            existing = db.query(Product).filter(Product.url == data["url"]).first()
            
            if existing:
                # ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸
                existing.title = data["title"]
                existing.brand = data["brand"]
                existing.price = data["price"]
                existing.updated_at = datetime.utcnow()
                
                # Seller ì •ë³´ë„ ì—…ë°ì´íŠ¸
                if existing.seller:
                    existing.seller.company = data["seller_info"]["company"]
                    existing.seller.brand = data["seller_info"]["brand"]
                    existing.seller.biz_num = data["seller_info"]["biz_num"]
                    existing.seller.license = data["seller_info"]["license"]
                    existing.seller.contact = data["seller_info"]["contact"]
                    existing.seller.email = data["seller_info"]["email"]
                    existing.seller.address = data["seller_info"]["address"]
            else:
                # ìƒˆ ë°ì´í„° ìƒì„±
                new_product = Product(
                    url=data["url"],
                    title=data["title"],
                    brand=data["brand"],
                    price=data["price"]
                )
                
                new_seller = Seller(
                    company=data["seller_info"]["company"],
                    brand=data["seller_info"]["brand"],
                    biz_num=data["seller_info"]["biz_num"],
                    license=data["seller_info"]["license"],
                    contact=data["seller_info"]["contact"],
                    email=data["seller_info"]["email"],
                    address=data["seller_info"]["address"]
                )
                new_product.seller = new_seller
                db.add(new_product)
            
            saved_count += 1
        
        db.commit()
        print(f"   ğŸ’¾ PostgreSQL ì €ì¥ ì™„ë£Œ: {saved_count}ê±´")
        
    except Exception as e:
        db.rollback()
        print(f"   âŒ PostgreSQL ì €ì¥ ì‹¤íŒ¨: {e}")
    finally:
        db.close()


def save_to_opensearch(docs: list):
    """
    OpenSearchì— Bulk Insert
    """
    if not docs:
        return
    
    try:
        success, failed = helpers.bulk(opensearch_client, docs)
        print(f"   ğŸ” OpenSearch ì €ì¥ ì™„ë£Œ: ì„±ê³µ {success}, ì‹¤íŒ¨ {failed}")
    except Exception as e:
        print(f"   âŒ OpenSearch ì €ì¥ ì‹¤íŒ¨: {e}")


async def run():
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False)
        context = await browser.new_context()
        page = await context.new_page()

        print(f"ğŸš€ [1ë‹¨ê³„] ë¬´ì‹ ì‚¬ '{SEARCH_KEYWORD}' ê²€ìƒ‰ ì‹œì‘")
        await page.goto(TARGET_URL, timeout=60000)
        
        # ìŠ¤í¬ë¡¤
        for i in range(SCROLL_COUNT):
            await page.keyboard.press("End")
            await asyncio.sleep(2)
            print(f"   â¬‡ï¸ ìŠ¤í¬ë¡¤ {i+1}/{SCROLL_COUNT}")

        # ìƒí’ˆ ë§í¬ ìˆ˜ì§‘
        print("   ğŸ” ìƒí’ˆ ë§í¬ ì¶”ì¶œ ì¤‘...")
        locators = page.locator("a[href*='/products/']")
        count = await locators.count()
        urls = set()
        for i in range(min(count, 20)):  # í…ŒìŠ¤íŠ¸ìš© 20ê°œ ì œí•œ
            href = await locators.nth(i).get_attribute("href")
            if href:
                if not href.startswith("http"):
                    href = "https://www.musinsa.com" + href
                urls.add(href)
        
        url_list = list(urls)
        print(f"   âœ… ìˆ˜ì§‘í•  ìƒí’ˆ ê°œìˆ˜: {len(url_list)}ê°œ")

        # -------------------------------------------------------
        # [ë°ì´í„° ìˆ˜ì§‘]
        # -------------------------------------------------------
        collected_data = []  # PostgreSQLìš©
        opensearch_docs = []  # OpenSearchìš©

        for idx, url in enumerate(url_list):
            try:
                print(f"   [{idx+1}] ì ‘ì†: {url}")
                await page.goto(url, timeout=30000)
                await page.wait_for_load_state("domcontentloaded")

                # íŒë§¤ì ì •ë³´ ë²„íŠ¼ í´ë¦­
                try:
                    seller_btn = page.locator("button", has_text="íŒë§¤ì ì •ë³´")
                    if await seller_btn.count() > 0:
                        expanded = await seller_btn.get_attribute("aria-expanded")
                        if expanded != "true":
                            await seller_btn.click()
                            await asyncio.sleep(0.5)
                except:
                    pass

                # ë°ì´í„° ì¶”ì¶œ í—¬í¼ í•¨ìˆ˜
                async def get_value(label):
                    locator = page.locator(f"//dt[contains(., '{label}')]/following-sibling::dd[1]")
                    if await locator.count() > 0:
                        return await locator.inner_text()
                    return ""

                # íŒë§¤ì ì •ë³´ ìˆ˜ì§‘
                info_company = await get_value("ìƒí˜¸")
                info_brand = await get_value("ë¸Œëœë“œ")
                info_biz_num = await get_value("ì‚¬ì—…ìë²ˆí˜¸")
                info_mail_order = await get_value("í†µì‹ íŒë§¤ì—…ì‹ ê³ ")
                info_contact = await get_value("ì—°ë½ì²˜")
                info_email = await get_value("E-mail")
                info_address = await get_value("ì˜ì—…ì†Œì¬ì§€")

                # ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘
                title_loc = page.locator("meta[property='og:title']").first
                title = await title_loc.get_attribute("content") if await title_loc.count() > 0 else "ì œëª©ì—†ìŒ"

                brand_loc = page.locator("meta[property='product:brand']").first
                brand_meta = await brand_loc.get_attribute("content") if await brand_loc.count() > 0 else info_brand

                price_loc = page.locator("meta[property='product:price:amount']").first
                if await price_loc.count() > 0:
                    price_text = await price_loc.get_attribute("content")
                    price_num = re.sub(r'[^0-9]', '', str(price_text))
                    price = int(price_num) if price_num else 0
                else:
                    price = 0

                # ë°ì´í„° êµ¬ì¡°í™”
                data = {
                    "url": url,
                    "title": title,
                    "brand": brand_meta,
                    "price": price,
                    "seller_info": {
                        "company": info_company,
                        "brand": info_brand,
                        "biz_num": info_biz_num,
                        "license": info_mail_order,
                        "contact": info_contact,
                        "email": info_email,
                        "address": info_address
                    }
                }
                collected_data.append(data)

                # OpenSearchìš© ë¬¸ì„œ
                opensearch_docs.append({
                    "_index": INDEX_NAME,
                    "_source": {
                        **data,
                        "created_at": datetime.now().isoformat()
                    }
                })

                print(f"      ğŸ‘‰ ìˆ˜ì§‘ì™„ë£Œ: {info_company} / {title[:20]}...")

            except Exception as e:
                print(f"      âŒ ì—ëŸ¬: {e}")
                continue

        # -------------------------------------------------------
        # [ë“€ì–¼ ì €ì¥] PostgreSQL + OpenSearch
        # -------------------------------------------------------
        if collected_data:
            print(f"\nğŸš€ ë°ì´í„° {len(collected_data)}ê±´ ì €ì¥ ì‹œì‘...")
            
            # 1. PostgreSQL ì €ì¥ (ì›ë³¸)
            save_to_postgres(collected_data)
            
            # 2. OpenSearch ì €ì¥ (ê²€ìƒ‰ìš©)
            save_to_opensearch(opensearch_docs)
            
            print("ğŸ‰ ë“€ì–¼ ì €ì¥ ì™„ë£Œ!")
        
        await browser.close()


if __name__ == "__main__":
    asyncio.run(run())
