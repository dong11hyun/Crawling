"""
ë¬´ì‹ ì‚¬ í¬ë¡¤ë§ DAG (v3 - XCom ìµœì í™”)
- ì†ŒëŸ‰ ë°ì´í„°: XCom ì§ì ‘ ì „ë‹¬
- ëŒ€ìš©ëŸ‰ ë°ì´í„°: íŒŒì¼ë¡œ ì €ì¥ í›„ ê²½ë¡œ ì „ë‹¬
- src/tasks/xcom_utils.py ì‚¬ìš©
"""
from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
import sys
import logging

# src í´ë”ë¥¼ Python pathì— ì¶”ê°€
sys.path.insert(0, '/opt/airflow/src')

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ========================================
# DAG ê¸°ë³¸ ì„¤ì •
# ========================================
default_args = {
    'owner': 'musinsa-team',
    'depends_on_past': False,
    'start_date': datetime(2026, 1, 1),
    'retries': 3,
    'retry_delay': timedelta(minutes=5),
    'retry_exponential_backoff': True,
    'max_retry_delay': timedelta(minutes=30),
}

dag = DAG(
    'musinsa_crawl_dag',
    default_args=default_args,
    description='ë¬´ì‹ ì‚¬ ìƒí’ˆ ë°ì´í„° ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸ (v3 - XCom ìµœì í™”)',
    schedule_interval='0 6 * * *',
    catchup=False,
    max_active_runs=1,
    tags=['musinsa', 'crawling', 'production'],
)


# ========================================
# Task í•¨ìˆ˜ë“¤ (XCom ìµœì í™” ì ìš©)
# ========================================
def run_crawl_task(**context):
    """
    í¬ë¡¤ë§ Task
    - ë°ì´í„° í¬ê¸°ì— ë”°ë¼ XCom ë˜ëŠ” íŒŒì¼ ì‚¬ìš©
    """
    from tasks.crawl_task import crawl_musinsa
    from tasks.xcom_utils import should_use_file, save_to_file
    
    # í¬ë¡¤ë§ ì‹¤í–‰
    data = crawl_musinsa(
        keyword="íŒ¨ë”©",
        scroll_count=2,
        max_products=15
    )
    
    ti = context['ti']
    
    # ë°ì´í„° í¬ê¸°ì— ë”°ë¼ ì „ë‹¬ ë°©ì‹ ê²°ì •
    if should_use_file(data):
        # ëŒ€ìš©ëŸ‰: íŒŒì¼ë¡œ ì €ì¥ í›„ ê²½ë¡œ ì „ë‹¬
        filepath = save_to_file(data, prefix="crawl")
        ti.xcom_push(key='crawled_data_path', value=filepath)
        ti.xcom_push(key='use_file', value=True)
        logger.info(f"ğŸ“ ëŒ€ìš©ëŸ‰ ë°ì´í„° â†’ íŒŒì¼ ì €ì¥: {filepath}")
    else:
        # ì†ŒëŸ‰: XCom ì§ì ‘ ì „ë‹¬
        ti.xcom_push(key='crawled_data', value=data)
        ti.xcom_push(key='use_file', value=False)
        logger.info(f"ğŸ“¦ ì†ŒëŸ‰ ë°ì´í„° â†’ XCom ì§ì ‘ ì „ë‹¬")
    
    return len(data)


def run_validate_task(**context):
    """
    ê²€ì¦ Task
    - XCom ë˜ëŠ” íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ
    """
    from tasks.validate_task import validate_products
    from tasks.xcom_utils import load_from_file, should_use_file, save_to_file
    
    ti = context['ti']
    use_file = ti.xcom_pull(key='use_file', task_ids='crawl_task')
    
    # ë°ì´í„° ë¡œë“œ (íŒŒì¼ ë˜ëŠ” XCom)
    if use_file:
        filepath = ti.xcom_pull(key='crawled_data_path', task_ids='crawl_task')
        data = load_from_file(filepath)
        logger.info(f"ğŸ“ íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ: {filepath}")
    else:
        data = ti.xcom_pull(key='crawled_data', task_ids='crawl_task')
        logger.info(f"ğŸ“¦ XComì—ì„œ ë°ì´í„° ë¡œë“œ")
    
    if not data:
        raise ValueError("í¬ë¡¤ë§ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
    
    # ê²€ì¦ ì‹¤í–‰
    valid_data, invalid_count = validate_products(data)
    
    # ê²°ê³¼ ì „ë‹¬ (í¬ê¸°ì— ë”°ë¼)
    if should_use_file(valid_data):
        filepath = save_to_file(valid_data, prefix="valid")
        ti.xcom_push(key='valid_data_path', value=filepath)
        ti.xcom_push(key='valid_use_file', value=True)
    else:
        ti.xcom_push(key='valid_data', value=valid_data)
        ti.xcom_push(key='valid_use_file', value=False)
    
    return len(valid_data)


def run_load_task(**context):
    """
    ì €ì¥ Task
    - XCom ë˜ëŠ” íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ
    """
    from tasks.load_task import load_to_storage
    from tasks.xcom_utils import load_from_file
    
    ti = context['ti']
    use_file = ti.xcom_pull(key='valid_use_file', task_ids='validate_task')
    
    # ë°ì´í„° ë¡œë“œ
    if use_file:
        filepath = ti.xcom_pull(key='valid_data_path', task_ids='validate_task')
        data = load_from_file(filepath)
    else:
        data = ti.xcom_pull(key='valid_data', task_ids='validate_task')
    
    if not data:
        return {"postgres": 0, "opensearch": 0}
    
    # ì €ì¥ ì‹¤í–‰
    result = load_to_storage(data)
    
    return result


def run_cleanup_task(**context):
    """
    ì •ë¦¬ Task - 7ì¼ ì´ìƒ ëœ ì„ì‹œ íŒŒì¼ ì‚­ì œ
    """
    from tasks.xcom_utils import cleanup_old_files
    
    deleted = cleanup_old_files(days=7)
    return deleted


# ========================================
# Task ì •ì˜
# ========================================
crawl_task = PythonOperator(
    task_id='crawl_task',
    python_callable=run_crawl_task,
    dag=dag,
)

validate_task = PythonOperator(
    task_id='validate_task',
    python_callable=run_validate_task,
    dag=dag,
)

load_task = PythonOperator(
    task_id='load_task',
    python_callable=run_load_task,
    dag=dag,
)

cleanup_task = PythonOperator(
    task_id='cleanup_task',
    python_callable=run_cleanup_task,
    dag=dag,
)

# ========================================
# Task ì˜ì¡´ì„±
# ========================================
crawl_task >> validate_task >> load_task >> cleanup_task
